from llm import generate_response  # your LLM wrapper
from models import ParsedPrompt
import prompts

